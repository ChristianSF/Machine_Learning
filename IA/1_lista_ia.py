# -*- coding: utf-8 -*-
"""1_Lista_IA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hx3fnLpy_rPNMbelD1Qog2VkXg8t4JGy

#Lista 1
##Importando as bibliotecas e módulos que serão utilizados
"""

import pandas as pd 
import numpy as np #Biblioteca matemática, para caso precise fazer alguma alteração nos vetores
from sklearn.datasets import load_iris #Carregar conjunto de dados 
from sklearn import tree #Carregar modelo
from sklearn.model_selection import train_test_split #Separar em dados de treino e teste
from sklearn.metrics import accuracy_score, confusion_matrix #Métricas para medir a precisão do modelo
import matplotlib.pyplot as plt #Plotar gráficos básicos
import seaborn as sns #Plotar gráficos mais elaborados
import graphviz #Plotar estrutura da árvore de decisão

"""Carregando dados que serão utilizados"""

dados = load_iris()
dados

"""Nome de cada classe"""

dados.target_names

dados.target

"""Separando os dados e o alvo/classes"""

x = dados.data
y = dados.target

"""*   Transformando o array em um DataFrame, para que possa ser mostrado num gráfico;
*   Plotando um gráfico para ver como o conjunto de dados se comportam.
"""

dados_grafico = pd.DataFrame(x)
sns.pairplot(dados_grafico)

"""Separando os dados em duas partes, treino e teste. Isso serve para que o modelo seja treinado e não ocorra o overfitting, ou seja, o sobre-ajuste do nosso conjunto de dados."""

x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, random_state = 1, test_size=0.3)
print("X Treino: ", len(x_treino))
print("Y Treino: ", len(y_treino))

print("Tamanho dos dados X Teste: ", len(x_teste))
print("Tamanho dos dados Y Teste: ", len(y_teste))

"""Criando um objeto Decision Tree e fazendo o treinamento do modelo, com os dados de treino."""

arvore = tree.DecisionTreeClassifier()
arvore.fit(x_treino, y_treino)

"""Mostrando a árvore, suas decisões e peso de cada uma delas. Além do percurso que ela fez para tomar cada decisão."""

fig, eixos = plt.subplots(nrows=1, ncols=1, figsize=(10,10))
tree.plot_tree(arvore, feature_names=dados.feature_names,  class_names=dados.target_names,  filled=True);

"""Aqui, podemos ver a importancia de cada atributo do conjunto de dados utilizado, para nosso algoritmo escolhido."""

arvore.feature_importances_

"""Fazendo a predição com os dados de teste"""

predicao = arvore.predict(x_teste)
predicao

"""Calculando a acurácia do modelo, a acurácia é usada para medir a performace do modelo, nos diz o quanto das classificações o modelo acertou. Essa medida varia entre 0 e 1.

Neste caso, 0.95 é um ótimo resultado, nos diz que o modelo não sofreu um overfitting.
"""

acc = accuracy_score(y_teste, predicao)
acc

"""##Matriz de Confusão

Uma matriz de confusão nos proporciona uma visualização do desempenho do algoritmo utilizado, sempre gerando uma matriz quadrada. Neste conjunto de dados, temos 3 classes, Setosa, Versicolor e Virginica, que são as espécies de flores. 

Essas classes, representam cada coluna da matriz, os valores podem mudar cada vez que o algoritmo for rodado.
"""

confusao = confusion_matrix(y_teste, predicao)
confusao

"""#Ex-2

##Primeira parte - Criterion Entropy

Como o "Criterion" padrão é o "gini", passamos como paramentro "entropy"
"""

arvore = tree.DecisionTreeClassifier(criterion="entropy")
arvore.fit(x_treino, y_treino)

arvore.feature_importances_

predicao_1 = arvore.predict(x_teste)
predicao_1

acc_1 = accuracy_score(y_teste, predicao_1)
acc_1

"""##Segunda Parte - Splitter Random

Como o "Splitter" padrão, é "best", aqui passamos "random"
"""

arvore = tree.DecisionTreeClassifier(splitter="random")
arvore.fit(x_treino, y_treino)

arvore.feature_importances_

predicao_2 = arvore.predict(x_teste)
predicao_2

"""Até aqui, esse foi o maior valor de acurácia que obtive neste notebook. Podemos ver que o atributo "**petal width (cm)**", foi escolhido com um peso maior que os outros.

Rodei esse notebook algumas vezes e essa acurácia variou bastante, indo dá maior, para a menor.
"""

acc_2 = accuracy_score(y_teste, predicao_2)
acc_2

"""##Terceira Parte - Max Depth 2

Passando "max_depth" igual a 2. Lembrando que o parâmetro padrão é "None".
"""

arvore = tree.DecisionTreeClassifier(max_depth=2)
arvore.fit(x_treino, y_treino)

arvore.feature_importances_

predicao_3 = arvore.predict(x_teste)
predicao_3

acc_3 = accuracy_score(y_teste, predicao_3)
acc_3

"""##Quarta Parte - Max Depth 4

Passando "max_depth" igual á 4.
"""

arvore = tree.DecisionTreeClassifier(max_depth=4)
arvore.fit(x_treino, y_treino)

arvore.feature_importances_

predicao_4 = arvore.predict(x_teste)
predicao_4

acc_4 = accuracy_score(y_teste, predicao_4)
acc_4

"""##Quinta Parte - Min Samples Split 10"""

arvore = tree.DecisionTreeClassifier(min_samples_split=10)
arvore.fit(x_treino, y_treino)

arvore.feature_importances_

predicao_5 = arvore.predict(x_teste)
predicao_5

acc_5 = accuracy_score(y_teste, predicao_5)
acc_5

"""#Resultados

Juntei as acurácias de todos os modelos, para plotar um gráfico e deixar mais visual essas medidas.
"""

todas_pred = [acc, acc_1, acc_2, acc_3, acc_4, acc_5]
todas_pred

plt.plot(todas_pred)
plt.grid(True)
plt.title("Acurácia de cada modelo")
plt.xlabel("Modelos")
plt.ylabel("Acurácia")
plt.show()

"""Este gráfico nos mostra o quanto a acurácia de cada modelo variou, mudando apenas os parâmetros passados para o objeto. Isso já responde nossa pergunta 3.

Sim, as árvores são diferentes. Apesar de o algoritmo usado ser o mesmo, os parametros passados foram diferentes, assim como os pesos de cada atributo e o caminho feito pelo modelo. O que fez com que sua acurácia mudasse.
"""
